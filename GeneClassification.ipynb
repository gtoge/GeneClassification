{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "GeneClassification.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gtoge/GeneClassification/blob/master/GeneClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJpeYCy3rj5q",
        "colab_type": "text"
      },
      "source": [
        "# Personalized Medicine: Redefining Cancer TreatmentÂ¶\n",
        "Predict the effect of Genetic Variants to enable Personalized Medicine The problem link:https://www.kaggle.com/c/msk-redefining-cancer-treatment This was launched by Memorial Sloan Kettering Cancer Center (MSKCC).Log Loss is the recomended scoring matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKgMcGVOrj5u",
        "colab_type": "text"
      },
      "source": [
        "# Steps to take\n",
        "- problem statement\n",
        "- loading data\n",
        "- analysing the data\n",
        "- processing the data\n",
        "- feature extraction\n",
        "- training classifier\n",
        "- testing\n",
        "- conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf6oA8CYrj5w",
        "colab_type": "text"
      },
      "source": [
        "# Used Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwVPtaKArj5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from scipy.sparse import  hstack\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import linear_model\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.calibration import CalibratedClassifierCV,calibration_curve\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import log_loss,accuracy_score,classification_report,confusion_matrix\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9X_qrcHrj55",
        "colab_type": "text"
      },
      "source": [
        " # Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6MqtW_6rj57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# start with loading data\n",
        "# Loading training_variants. Its a comma seperated file\n",
        "data_variants = pd.read_csv('training_variants')\n",
        "# Loading training_text dataset. This is seperated by ||\n",
        "data_text =pd.read_csv(\"training_text\",sep=\"\\|\\|\",engine=\"python\",names=[\"ID\",\"TEXT\"],skiprows=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90zP54uurj6B",
        "colab_type": "text"
      },
      "source": [
        "# analysing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWynBqv6rj6D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "f0f18551-049c-4550-fca8-996abbb8f610"
      },
      "source": [
        "# Here we try to see nature of data,get some information and statistics about the data.\n",
        "#data_variants\n",
        "print(data_variants.head(5))\n",
        "print(data_variants.info())\n",
        "print(data_variants.describe())\n",
        "print(data_variants.shape)\n",
        "print(data_variants.columns)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   ID    Gene             Variation  Class\n",
            "0   0  FAM58A  Truncating Mutations      1\n",
            "1   1     CBL                 W802*      2\n",
            "2   2     CBL                 Q249E      2\n",
            "3   3     CBL                 N454D      3\n",
            "4   4     CBL                 L399V      4\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3321 entries, 0 to 3320\n",
            "Data columns (total 4 columns):\n",
            "ID           3321 non-null int64\n",
            "Gene         3321 non-null object\n",
            "Variation    3321 non-null object\n",
            "Class        3321 non-null int64\n",
            "dtypes: int64(2), object(2)\n",
            "memory usage: 103.9+ KB\n",
            "None\n",
            "                ID        Class\n",
            "count  3321.000000  3321.000000\n",
            "mean   1660.000000     4.365854\n",
            "std     958.834449     2.309781\n",
            "min       0.000000     1.000000\n",
            "25%     830.000000     2.000000\n",
            "50%    1660.000000     4.000000\n",
            "75%    2490.000000     7.000000\n",
            "max    3320.000000     9.000000\n",
            "(3321, 4)\n",
            "Index(['ID', 'Gene', 'Variation', 'Class'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFXg2JXIrj6L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "3b21cdd1-2a56-46c3-95fd-7e022be9db3a"
      },
      "source": [
        "#data_Text\n",
        "print(data_text.head(5))\n",
        "print(data_text.info())\n",
        "print(data_text.describe())\n",
        "print(data_text.shape)\n",
        "print(data_text.columns)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   ID                                               TEXT\n",
            "0   0  Cyclin-dependent kinases (CDKs) regulate a var...\n",
            "1   1   Abstract Background  Non-small cell lung canc...\n",
            "2   2   Abstract Background  Non-small cell lung canc...\n",
            "3   3  Recent evidence has demonstrated that acquired...\n",
            "4   4  Oncogenic mutations in the monomeric Casitas B...\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1695 entries, 0 to 1694\n",
            "Data columns (total 2 columns):\n",
            "ID      1695 non-null int64\n",
            "TEXT    1691 non-null object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 26.6+ KB\n",
            "None\n",
            "                ID\n",
            "count  1695.000000\n",
            "mean    847.000000\n",
            "std     489.448669\n",
            "min       0.000000\n",
            "25%     423.500000\n",
            "50%     847.000000\n",
            "75%    1270.500000\n",
            "max    1694.000000\n",
            "(1695, 2)\n",
            "Index(['ID', 'TEXT'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcL0Kq4vrj6R",
        "colab_type": "text"
      },
      "source": [
        "# Data Processsing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFa0sMVYrj6T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "ef6714a9-cf40-442f-eb19-96691d617cf7"
      },
      "source": [
        "#merging both text and variants data base on Id\n",
        "result_data = pd.merge(data_variants, data_text,on='ID', how='left')\n",
        "result_data=result_data[['ID','Gene','Variation','TEXT','Class']]\n",
        "print(result_data.head(5)) #viewing the resulting data\n",
        "result_data.dtypes"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   ID    Gene  ...                                               TEXT Class\n",
            "0   0  FAM58A  ...  Cyclin-dependent kinases (CDKs) regulate a var...     1\n",
            "1   1     CBL  ...   Abstract Background  Non-small cell lung canc...     2\n",
            "2   2     CBL  ...   Abstract Background  Non-small cell lung canc...     2\n",
            "3   3     CBL  ...  Recent evidence has demonstrated that acquired...     3\n",
            "4   4     CBL  ...  Oncogenic mutations in the monomeric Casitas B...     4\n",
            "\n",
            "[5 rows x 5 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID            int64\n",
              "Gene         object\n",
              "Variation    object\n",
              "TEXT         object\n",
              "Class         int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdvibVcorj6Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "6e0a5574-73b2-4e70-98c4-1ee2ffc31575"
      },
      "source": [
        "# checking and handling Missing data \n",
        "result_data[result_data.isnull().any(axis=1)]\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Gene</th>\n",
              "      <th>Variation</th>\n",
              "      <th>TEXT</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1109</th>\n",
              "      <td>1109</td>\n",
              "      <td>FANCA</td>\n",
              "      <td>S1088F</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1277</th>\n",
              "      <td>1277</td>\n",
              "      <td>ARID5B</td>\n",
              "      <td>Truncating Mutations</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1407</th>\n",
              "      <td>1407</td>\n",
              "      <td>FGFR3</td>\n",
              "      <td>K508M</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1639</th>\n",
              "      <td>1639</td>\n",
              "      <td>FLT1</td>\n",
              "      <td>Amplification</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1695</th>\n",
              "      <td>1695</td>\n",
              "      <td>PMS2</td>\n",
              "      <td>R802*</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3316</th>\n",
              "      <td>3316</td>\n",
              "      <td>RUNX1</td>\n",
              "      <td>D171N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3317</th>\n",
              "      <td>3317</td>\n",
              "      <td>RUNX1</td>\n",
              "      <td>A122*</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3318</th>\n",
              "      <td>3318</td>\n",
              "      <td>RUNX1</td>\n",
              "      <td>Fusions</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3319</th>\n",
              "      <td>3319</td>\n",
              "      <td>RUNX1</td>\n",
              "      <td>R80C</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3320</th>\n",
              "      <td>3320</td>\n",
              "      <td>RUNX1</td>\n",
              "      <td>K83E</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1630 rows Ã 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        ID    Gene             Variation TEXT  Class\n",
              "1109  1109   FANCA                S1088F  NaN      1\n",
              "1277  1277  ARID5B  Truncating Mutations  NaN      1\n",
              "1407  1407   FGFR3                 K508M  NaN      6\n",
              "1639  1639    FLT1         Amplification  NaN      6\n",
              "1695  1695    PMS2                 R802*  NaN      1\n",
              "...    ...     ...                   ...  ...    ...\n",
              "3316  3316   RUNX1                 D171N  NaN      4\n",
              "3317  3317   RUNX1                 A122*  NaN      1\n",
              "3318  3318   RUNX1               Fusions  NaN      1\n",
              "3319  3319   RUNX1                  R80C  NaN      4\n",
              "3320  3320   RUNX1                  K83E  NaN      4\n",
              "\n",
              "[1630 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX9yaBxurj6f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "255dbfc0-b49a-4315-9916-66303626f8e3"
      },
      "source": [
        "# Imputing Missing data\n",
        "# there are only missing Text we will replace them with a cobination of gene and variant\n",
        "result_data.loc[result_data['TEXT'].isnull(),'TEXT'] = result_data['Gene'] +' '+result_data['Variation']\n",
        "# verifying our imputation\n",
        "result_data[result_data.isnull().any(axis=1)]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Gene</th>\n",
              "      <th>Variation</th>\n",
              "      <th>TEXT</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [ID, Gene, Variation, TEXT, Class]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-TjJEOmrj6l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "ab7f3b89-fef7-43be-be85-2fac63bd10c4"
      },
      "source": [
        "# Checking the distribution of each paramater \n",
        "TEXT_Distribution=result_data.groupby('Class').TEXT.count()\n",
        "Gene_Distribution=result_data.groupby('Class').Gene.count()\n",
        "Variation_Distribution=result_data.groupby('Class').Variation.count()\n",
        "print(TEXT_Distribution)\n",
        "print(Gene_Distribution)\n",
        "print(Variation_Distribution)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class\n",
            "1    568\n",
            "2    452\n",
            "3     89\n",
            "4    686\n",
            "5    242\n",
            "6    275\n",
            "7    953\n",
            "8     19\n",
            "9     37\n",
            "Name: TEXT, dtype: int64\n",
            "Class\n",
            "1    568\n",
            "2    452\n",
            "3     89\n",
            "4    686\n",
            "5    242\n",
            "6    275\n",
            "7    953\n",
            "8     19\n",
            "9     37\n",
            "Name: Gene, dtype: int64\n",
            "Class\n",
            "1    568\n",
            "2    452\n",
            "3     89\n",
            "4    686\n",
            "5    242\n",
            "6    275\n",
            "7    953\n",
            "8     19\n",
            "9     37\n",
            "Name: Variation, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ7LI0g_rj6r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "outputId": "0573758f-0869-4513-9585-1a1fe7a3251b"
      },
      "source": [
        "# Visualising using a bar shart\n",
        "TEXT_Distribution.plot(kind='bar' )\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel(' Number of Data points per Class')\n",
        "plt.title('Distribution of TEXT')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "Gene_Distribution.plot(kind='bar' )\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel(' Number of Data points per Class')\n",
        "plt.title('Distribution Genes')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "Variation_Distribution.plot(kind='bar' )\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel(' Number of Data points per Class')\n",
        "plt.title('Distribution of Gene Variation')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAETCAYAAADH1SqlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAETCAYAAADH1SqlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzMws1/8HgCc5ezP9+CUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAETCAYAAADH1SqlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7fC0aRlrj6x",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning the data in order to metigate the problem of dimesionality\n",
        "-by applying feature engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF_f8SbArj6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# some functions used\n",
        "# replace space within the gene and variation columns with _\n",
        "def GeneColumn(Gene):\n",
        "    Gene.replace('\\s+', '_')\n",
        "    return Gene\n",
        "\n",
        "def VariationColumn(Variation):\n",
        "    Variation.replace('\\s+', '_')\n",
        "    return Variation\n",
        "# replacing special characters with a space and double space with sing space\n",
        "def TEXTColumn(TEXT):\n",
        "    TEXT.replace('[^a-zA-Z0-9\\n]', ' ')\n",
        "    TEXT.replace('\\s+',' ',)\n",
        "    #Stemmer\n",
        "    Wln=WordNetLemmatizer()\n",
        "    TEXT=[Wln.lemmatize(word) for word in TEXT]\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYcMepiHrj65",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9f75ee51-c513-472d-ee5f-6e3377b229d6"
      },
      "source": [
        "# Running the function\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "GeneColumn(result_data.Gene)\n",
        "VariationColumn(result_data.Variation)\n",
        "TEXTColumn(result_data.TEXT)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQml1H5Mrj6-",
        "colab_type": "text"
      },
      "source": [
        "# Feature Extraction\n",
        "- CountVectorizer\n",
        "- TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtRPqOnKrj7B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4200bd96-4492-4962-f06f-865c2278ac70"
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vecGene= vectorizer.fit_transform(result_data.Gene)\n",
        "# Checking the shape of the data\n",
        "print(vecGene.shape)\n",
        "# checking the Column \n",
        "vectorizer.get_feature_names()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3321, 263)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abl1',\n",
              " 'acvr1',\n",
              " 'ago2',\n",
              " 'akt1',\n",
              " 'akt2',\n",
              " 'akt3',\n",
              " 'alk',\n",
              " 'apc',\n",
              " 'ar',\n",
              " 'araf',\n",
              " 'arid1a',\n",
              " 'arid1b',\n",
              " 'arid2',\n",
              " 'arid5b',\n",
              " 'asxl1',\n",
              " 'asxl2',\n",
              " 'atm',\n",
              " 'atr',\n",
              " 'atrx',\n",
              " 'aurka',\n",
              " 'aurkb',\n",
              " 'axin1',\n",
              " 'axl',\n",
              " 'b2m',\n",
              " 'bap1',\n",
              " 'bard1',\n",
              " 'bcl10',\n",
              " 'bcl2',\n",
              " 'bcl2l11',\n",
              " 'bcor',\n",
              " 'braf',\n",
              " 'brca1',\n",
              " 'brca2',\n",
              " 'brd4',\n",
              " 'brip1',\n",
              " 'btk',\n",
              " 'card11',\n",
              " 'carm1',\n",
              " 'casp8',\n",
              " 'cbl',\n",
              " 'ccnd1',\n",
              " 'ccnd2',\n",
              " 'ccnd3',\n",
              " 'ccne1',\n",
              " 'cdh1',\n",
              " 'cdk12',\n",
              " 'cdk4',\n",
              " 'cdk6',\n",
              " 'cdk8',\n",
              " 'cdkn1a',\n",
              " 'cdkn1b',\n",
              " 'cdkn2a',\n",
              " 'cdkn2b',\n",
              " 'cdkn2c',\n",
              " 'cebpa',\n",
              " 'chek2',\n",
              " 'cic',\n",
              " 'crebbp',\n",
              " 'ctcf',\n",
              " 'ctla4',\n",
              " 'ctnnb1',\n",
              " 'ddr2',\n",
              " 'dicer1',\n",
              " 'dnmt3a',\n",
              " 'dnmt3b',\n",
              " 'dusp4',\n",
              " 'egfr',\n",
              " 'eif1ax',\n",
              " 'elf3',\n",
              " 'ep300',\n",
              " 'epas1',\n",
              " 'epcam',\n",
              " 'erbb2',\n",
              " 'erbb3',\n",
              " 'erbb4',\n",
              " 'ercc2',\n",
              " 'ercc3',\n",
              " 'ercc4',\n",
              " 'erg',\n",
              " 'errfi1',\n",
              " 'esr1',\n",
              " 'etv1',\n",
              " 'etv6',\n",
              " 'ewsr1',\n",
              " 'ezh2',\n",
              " 'fam58a',\n",
              " 'fanca',\n",
              " 'fancc',\n",
              " 'fat1',\n",
              " 'fbxw7',\n",
              " 'fgf19',\n",
              " 'fgf3',\n",
              " 'fgf4',\n",
              " 'fgfr1',\n",
              " 'fgfr2',\n",
              " 'fgfr3',\n",
              " 'fgfr4',\n",
              " 'flt1',\n",
              " 'flt3',\n",
              " 'foxa1',\n",
              " 'foxl2',\n",
              " 'foxo1',\n",
              " 'foxp1',\n",
              " 'fubp1',\n",
              " 'gata3',\n",
              " 'gli1',\n",
              " 'gna11',\n",
              " 'gnaq',\n",
              " 'gnas',\n",
              " 'h3f3a',\n",
              " 'hist1h1c',\n",
              " 'hla',\n",
              " 'hnf1a',\n",
              " 'hras',\n",
              " 'idh1',\n",
              " 'idh2',\n",
              " 'igf1r',\n",
              " 'ikbke',\n",
              " 'ikzf1',\n",
              " 'il7r',\n",
              " 'inpp4b',\n",
              " 'jak1',\n",
              " 'jak2',\n",
              " 'jun',\n",
              " 'kdm5a',\n",
              " 'kdm5c',\n",
              " 'kdm6a',\n",
              " 'kdr',\n",
              " 'keap1',\n",
              " 'kit',\n",
              " 'klf4',\n",
              " 'kmt2a',\n",
              " 'kmt2b',\n",
              " 'kmt2c',\n",
              " 'kmt2d',\n",
              " 'knstrn',\n",
              " 'kras',\n",
              " 'lats1',\n",
              " 'lats2',\n",
              " 'map2k1',\n",
              " 'map2k2',\n",
              " 'map2k4',\n",
              " 'map3k1',\n",
              " 'mapk1',\n",
              " 'mdm2',\n",
              " 'mdm4',\n",
              " 'med12',\n",
              " 'mef2b',\n",
              " 'men1',\n",
              " 'met',\n",
              " 'mga',\n",
              " 'mlh1',\n",
              " 'mpl',\n",
              " 'msh2',\n",
              " 'msh6',\n",
              " 'mtor',\n",
              " 'myc',\n",
              " 'mycn',\n",
              " 'myd88',\n",
              " 'myod1',\n",
              " 'ncor1',\n",
              " 'nf1',\n",
              " 'nf2',\n",
              " 'nfe2l2',\n",
              " 'nfkbia',\n",
              " 'nkx2',\n",
              " 'notch1',\n",
              " 'notch2',\n",
              " 'npm1',\n",
              " 'nras',\n",
              " 'nsd1',\n",
              " 'ntrk1',\n",
              " 'ntrk2',\n",
              " 'ntrk3',\n",
              " 'nup93',\n",
              " 'pak1',\n",
              " 'pax8',\n",
              " 'pbrm1',\n",
              " 'pdgfra',\n",
              " 'pdgfrb',\n",
              " 'pik3ca',\n",
              " 'pik3cb',\n",
              " 'pik3cd',\n",
              " 'pik3r1',\n",
              " 'pik3r2',\n",
              " 'pik3r3',\n",
              " 'pim1',\n",
              " 'pms1',\n",
              " 'pms2',\n",
              " 'pole',\n",
              " 'ppm1d',\n",
              " 'ppp2r1a',\n",
              " 'ppp6c',\n",
              " 'prdm1',\n",
              " 'ptch1',\n",
              " 'pten',\n",
              " 'ptpn11',\n",
              " 'ptprd',\n",
              " 'ptprt',\n",
              " 'rab35',\n",
              " 'rac1',\n",
              " 'rad21',\n",
              " 'rad50',\n",
              " 'rad51b',\n",
              " 'rad51c',\n",
              " 'rad51d',\n",
              " 'rad54l',\n",
              " 'raf1',\n",
              " 'rara',\n",
              " 'rasa1',\n",
              " 'rb1',\n",
              " 'rbm10',\n",
              " 'ret',\n",
              " 'rheb',\n",
              " 'rhoa',\n",
              " 'rictor',\n",
              " 'rit1',\n",
              " 'rnf43',\n",
              " 'ros1',\n",
              " 'rras2',\n",
              " 'runx1',\n",
              " 'rxra',\n",
              " 'rybp',\n",
              " 'sdhb',\n",
              " 'sdhc',\n",
              " 'setd2',\n",
              " 'sf3b1',\n",
              " 'shoc2',\n",
              " 'shq1',\n",
              " 'smad2',\n",
              " 'smad3',\n",
              " 'smad4',\n",
              " 'smarca4',\n",
              " 'smarcb1',\n",
              " 'smo',\n",
              " 'sos1',\n",
              " 'sox9',\n",
              " 'spop',\n",
              " 'src',\n",
              " 'srsf2',\n",
              " 'stag2',\n",
              " 'stat3',\n",
              " 'stk11',\n",
              " 'tcf3',\n",
              " 'tcf7l2',\n",
              " 'tert',\n",
              " 'tet1',\n",
              " 'tet2',\n",
              " 'tgfbr1',\n",
              " 'tgfbr2',\n",
              " 'tmprss2',\n",
              " 'tp53',\n",
              " 'tp53bp1',\n",
              " 'tsc1',\n",
              " 'tsc2',\n",
              " 'u2af1',\n",
              " 'vegfa',\n",
              " 'vhl',\n",
              " 'whsc1',\n",
              " 'whsc1l1',\n",
              " 'xpo1',\n",
              " 'xrcc2',\n",
              " 'yap1']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI54fwm5rj7I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "765d78d0-06d1-46b1-88ab-1ee43cce3cb5"
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vecVariation= vectorizer.fit_transform(result_data.Variation)\n",
        "# Checking the shape of the data\n",
        "print(vecVariation.shape)\n",
        "# checking the Column \n",
        "vectorizer.get_feature_names()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3321, 3021)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['11',\n",
              " '126',\n",
              " '13',\n",
              " '17',\n",
              " '19',\n",
              " '1_2009trunc',\n",
              " '20',\n",
              " '2010_2471trunc',\n",
              " '256_286trunc',\n",
              " '385_418del',\n",
              " '422_605trunc',\n",
              " '51',\n",
              " '533_534del',\n",
              " '534_536del',\n",
              " '550_592del',\n",
              " '560_561inser',\n",
              " '596_619splice',\n",
              " '6a',\n",
              " '963_d1010splice',\n",
              " '981_1028splice',\n",
              " 'a1020v',\n",
              " 'a1022e',\n",
              " 'a1065t',\n",
              " 'a1066v',\n",
              " 'a1099t',\n",
              " 'a111p',\n",
              " 'a1131t',\n",
              " 'a113_splice',\n",
              " 'a1170v',\n",
              " 'a11_g12insga',\n",
              " 'a1200v',\n",
              " 'a120s',\n",
              " 'a121e',\n",
              " 'a121p',\n",
              " 'a121v',\n",
              " 'a122',\n",
              " 'a1234t',\n",
              " 'a126d',\n",
              " 'a126g',\n",
              " 'a126s',\n",
              " 'a126v',\n",
              " 'a134d',\n",
              " 'a1374v',\n",
              " 'a1459p',\n",
              " 'a146t',\n",
              " 'a146v',\n",
              " 'a148t',\n",
              " 'a149p',\n",
              " 'a1519t',\n",
              " 'a151t',\n",
              " 'a159t',\n",
              " 'a161s',\n",
              " 'a161t',\n",
              " 'a1669s',\n",
              " 'a1685s',\n",
              " 'a1701p',\n",
              " 'a1708e',\n",
              " 'a1708v',\n",
              " 'a171v',\n",
              " 'a1752p',\n",
              " 'a1752v',\n",
              " 'a1789s',\n",
              " 'a1789t',\n",
              " 'a1823t',\n",
              " 'a1830t',\n",
              " 'a1843p',\n",
              " 'a1843t',\n",
              " 'a18d',\n",
              " 'a197t',\n",
              " 'a19v',\n",
              " 'a2034v',\n",
              " 'a205t',\n",
              " 'a209t',\n",
              " 'a211d',\n",
              " 'a232v',\n",
              " 'a2351g',\n",
              " 'a23e',\n",
              " 'a2425t',\n",
              " 'a246p',\n",
              " 'a263v',\n",
              " 'a2643g',\n",
              " 'a2717s',\n",
              " 'a272v',\n",
              " 'a2770t',\n",
              " 'a290t',\n",
              " 'a298t',\n",
              " 'a339v',\n",
              " 'a347t',\n",
              " 'a349p',\n",
              " 'a34d',\n",
              " 'a36p',\n",
              " 'a389t',\n",
              " 'a391e',\n",
              " 'a39p',\n",
              " 'a40e',\n",
              " 'a41p',\n",
              " 'a41t',\n",
              " 'a4419s',\n",
              " 'a459v',\n",
              " 'a500t',\n",
              " 'a502_y503dup',\n",
              " 'a504_y505ins',\n",
              " 'a530t',\n",
              " 'a530v',\n",
              " 'a532h',\n",
              " 'a546d',\n",
              " 'a57v',\n",
              " 'a598t',\n",
              " 'a598v',\n",
              " 'a59g',\n",
              " 'a59t',\n",
              " 'a60v',\n",
              " 'a614d',\n",
              " 'a617t',\n",
              " 'a627t',\n",
              " 'a633t',\n",
              " 'a633v',\n",
              " 'a634d',\n",
              " 'a634v',\n",
              " 'a636p',\n",
              " 'a648t',\n",
              " 'a677g',\n",
              " 'a707t',\n",
              " 'a717g',\n",
              " 'a723d',\n",
              " 'a727v',\n",
              " 'a728v',\n",
              " 'a72s',\n",
              " 'a72v',\n",
              " 'a750_e758del',\n",
              " 'a750_e758delinsp',\n",
              " 'a750p',\n",
              " 'a75p',\n",
              " 'a763_y764insfqea',\n",
              " 'a767_v769del',\n",
              " 'a767_v769dup',\n",
              " 'a77p',\n",
              " 'a77s',\n",
              " 'a77t',\n",
              " 'a829p',\n",
              " 'a859_l883delinsv',\n",
              " 'a864t',\n",
              " 'a883f',\n",
              " 'a883t',\n",
              " 'a889p',\n",
              " 'a8s',\n",
              " 'a919v',\n",
              " 'a95d',\n",
              " 'abl1',\n",
              " 'acpp',\n",
              " 'agk',\n",
              " 'ahcyl1',\n",
              " 'akap9',\n",
              " 'akt3',\n",
              " 'alk',\n",
              " 'amplification',\n",
              " 'ar',\n",
              " 'arv567es',\n",
              " 'atf1',\n",
              " 'atf7ip',\n",
              " 'atg7',\n",
              " 'baiap2l1',\n",
              " 'bcan',\n",
              " 'bcl2',\n",
              " 'bcor',\n",
              " 'bcr',\n",
              " 'bicc1',\n",
              " 'bin2',\n",
              " 'binding',\n",
              " 'braf',\n",
              " 'brd4',\n",
              " 'btbd1',\n",
              " 'c105f',\n",
              " 'c1156f',\n",
              " 'c1156y',\n",
              " 'c121s',\n",
              " 'c124n',\n",
              " 'c124r',\n",
              " 'c124s',\n",
              " 'c125s',\n",
              " 'c1265s',\n",
              " 'c134w',\n",
              " 'c135r',\n",
              " 'c135s',\n",
              " 'c135y',\n",
              " 'c1365y',\n",
              " 'c136r',\n",
              " 'c136y',\n",
              " 'c1385',\n",
              " 'c141y',\n",
              " 'c1483f',\n",
              " 'c1483r',\n",
              " 'c1483w',\n",
              " 'c1483y',\n",
              " 'c157y',\n",
              " 'c1697r',\n",
              " 'c1767s',\n",
              " 'c176f',\n",
              " 'c1787s',\n",
              " 'c18y',\n",
              " 'c2060g',\n",
              " 'c228t',\n",
              " 'c229r',\n",
              " 'c238f',\n",
              " 'c238s',\n",
              " 'c242f',\n",
              " 'c242s',\n",
              " 'c248t',\n",
              " 'c24r',\n",
              " 'c24y',\n",
              " 'c250t',\n",
              " 'c275s',\n",
              " 'c277q',\n",
              " 'c277r',\n",
              " 'c277w',\n",
              " 'c278f',\n",
              " 'c27a',\n",
              " 'c311r',\n",
              " 'c324y',\n",
              " 'c334s',\n",
              " 'c360r',\n",
              " 'c378r',\n",
              " 'c381a',\n",
              " 'c382r',\n",
              " 'c384r',\n",
              " 'c396r',\n",
              " 'c39r',\n",
              " 'c39s',\n",
              " 'c39y',\n",
              " 'c41y',\n",
              " 'c420r',\n",
              " 'c443y',\n",
              " 'c44f',\n",
              " 'c44y',\n",
              " 'c450_k451insmiewmi',\n",
              " 'c456_n468del',\n",
              " 'c456_r481del',\n",
              " 'c47g',\n",
              " 'c47s',\n",
              " 'c481s',\n",
              " 'c482r',\n",
              " 'c49y',\n",
              " 'c528s',\n",
              " 'c554w',\n",
              " 'c569y',\n",
              " 'c582f',\n",
              " 'c609y',\n",
              " 'c611y',\n",
              " 'c618r',\n",
              " 'c61g',\n",
              " 'c620r',\n",
              " 'c620y',\n",
              " 'c628y',\n",
              " 'c630r',\n",
              " 'c630y',\n",
              " 'c634r',\n",
              " 'c634s',\n",
              " 'c634w',\n",
              " 'c634y',\n",
              " 'c64g',\n",
              " 'c696y',\n",
              " 'c706f',\n",
              " 'c712r',\n",
              " 'c71y',\n",
              " 'c77f',\n",
              " 'c809g',\n",
              " 'c91a',\n",
              " 'c91s',\n",
              " 'cad',\n",
              " 'casp8l',\n",
              " 'ccdc170',\n",
              " 'ccdc6',\n",
              " 'ccnb3',\n",
              " 'ccnd1',\n",
              " 'cd74',\n",
              " 'cep110',\n",
              " 'cep85l',\n",
              " 'chtop',\n",
              " 'cic',\n",
              " 'copy',\n",
              " 'cpeb1',\n",
              " 'creb1',\n",
              " 'cul1',\n",
              " 'cux1',\n",
              " 'd1010h',\n",
              " 'd1010n',\n",
              " 'd1010y',\n",
              " 'd101y',\n",
              " 'd1029y',\n",
              " 'd1067a',\n",
              " 'd1067v',\n",
              " 'd1067y',\n",
              " 'd106a',\n",
              " 'd1071n',\n",
              " 'd107y',\n",
              " 'd108h',\n",
              " 'd108n',\n",
              " 'd1091n',\n",
              " 'd119n',\n",
              " 'd1203n',\n",
              " 'd121g',\n",
              " 'd1270g',\n",
              " 'd1280v',\n",
              " 'd130a',\n",
              " 'd1344h',\n",
              " 'd1349h',\n",
              " 'd1352y',\n",
              " 'd1384v',\n",
              " 'd1399y',\n",
              " 'd140g',\n",
              " 'd1420y',\n",
              " 'd153v',\n",
              " 'd1546n',\n",
              " 'd162g',\n",
              " 'd162h',\n",
              " 'd1692n',\n",
              " 'd1709a',\n",
              " 'd1709e',\n",
              " 'd171g',\n",
              " 'd171n',\n",
              " 'd1733g',\n",
              " 'd1739e',\n",
              " 'd1739g',\n",
              " 'd1739v',\n",
              " 'd1739y',\n",
              " 'd1778g',\n",
              " 'd1778h',\n",
              " 'd1778n',\n",
              " 'd1778y',\n",
              " 'd1810a',\n",
              " 'd1818g',\n",
              " 'd1853n',\n",
              " 'd186a',\n",
              " 'd194y',\n",
              " 'd2033n',\n",
              " 'd2312v',\n",
              " 'd245v',\n",
              " 'd24y',\n",
              " 'd2512g',\n",
              " 'd2512y',\n",
              " 'd252g',\n",
              " 'd254n',\n",
              " 'd257n',\n",
              " 'd258n',\n",
              " 'd2665g',\n",
              " 'd2723g',\n",
              " 'd2723h',\n",
              " 'd277h',\n",
              " 'd2870a',\n",
              " 'd287h',\n",
              " 'd289_d292del',\n",
              " 'd289del',\n",
              " 'd29h',\n",
              " 'd29y',\n",
              " 'd300h',\n",
              " 'd300n',\n",
              " 'd3095e',\n",
              " 'd3170g',\n",
              " 'd323h',\n",
              " 'd324n',\n",
              " 'd325a',\n",
              " 'd326n',\n",
              " 'd32a',\n",
              " 'd32h',\n",
              " 'd32n',\n",
              " 'd32y',\n",
              " 'd331g',\n",
              " 'd350g',\n",
              " 'd351h',\n",
              " 'd357y',\n",
              " 'd384n',\n",
              " 'd387v',\n",
              " 'd390y',\n",
              " 'd399n',\n",
              " 'd401n',\n",
              " 'd402y',\n",
              " 'd404g',\n",
              " 'd408e',\n",
              " 'd408h',\n",
              " 'd408y',\n",
              " 'd419del',\n",
              " 'd422n',\n",
              " 'd423n',\n",
              " 'd450e',\n",
              " 'd450h',\n",
              " 'd473g',\n",
              " 'd473h',\n",
              " 'd493a',\n",
              " 'd513y',\n",
              " 'd520n',\n",
              " 'd537e',\n",
              " 'd537y',\n",
              " 'd544h',\n",
              " 'd557h',\n",
              " 'd560y',\n",
              " 'd572a',\n",
              " 'd579del',\n",
              " 'd587h',\n",
              " 'd594a',\n",
              " 'd594e',\n",
              " 'd594g',\n",
              " 'd594n',\n",
              " 'd594v',\n",
              " 'd594y',\n",
              " 'd595v',\n",
              " 'd600_l601insfreyeyd',\n",
              " 'd603g',\n",
              " 'd603n',\n",
              " 'd609e',\n",
              " 'd60n',\n",
              " 'd617g',\n",
              " 'd61n',\n",
              " 'd61y',\n",
              " 'd631a',\n",
              " 'd631g',\n",
              " 'd641g',\n",
              " 'd641n',\n",
              " 'd646y',\n",
              " 'd65n',\n",
              " 'd661v',\n",
              " 'd661y',\n",
              " 'd67n',\n",
              " 'd67y',\n",
              " 'd717v',\n",
              " 'd737n',\n",
              " 'd74n',\n",
              " 'd74y',\n",
              " 'd761y',\n",
              " 'd769a',\n",
              " 'd769h',\n",
              " 'd769y',\n",
              " 'd770_n771insd',\n",
              " 'd770_n771insnpg',\n",
              " 'd770_n771insvdsvdnp',\n",
              " 'd770_p772dup',\n",
              " 'd806h',\n",
              " 'd808n',\n",
              " 'd814v',\n",
              " 'd816a',\n",
              " 'd816e',\n",
              " 'd816f',\n",
              " 'd816g',\n",
              " 'd816h',\n",
              " 'd816n',\n",
              " 'd816v',\n",
              " 'd816y',\n",
              " 'd820a',\n",
              " 'd820e',\n",
              " 'd820g',\n",
              " 'd821n',\n",
              " 'd835a',\n",
              " 'd835del',\n",
              " 'd835e',\n",
              " 'd835h',\n",
              " 'd835n',\n",
              " 'd835y',\n",
              " 'd837n',\n",
              " 'd839g',\n",
              " 'd83v',\n",
              " 'd842_h845del',\n",
              " 'd842_m844del',\n",
              " 'd842i',\n",
              " 'd842v',\n",
              " 'd842y',\n",
              " 'd845a',\n",
              " 'd846y',\n",
              " 'd84g',\n",
              " 'd84h',\n",
              " 'd84n',\n",
              " 'd84v',\n",
              " 'd84y',\n",
              " 'd86n',\n",
              " 'd887n',\n",
              " 'd927g',\n",
              " 'd92a',\n",
              " 'd92e',\n",
              " 'd92g',\n",
              " 'd92h',\n",
              " 'd92n',\n",
              " 'd92v',\n",
              " 'd935n',\n",
              " 'd96n',\n",
              " 'ddit3',\n",
              " 'deletion',\n",
              " 'deletions',\n",
              " 'delta',\n",
              " 'dna',\n",
              " 'dnmt3b7',\n",
              " 'domain',\n",
              " 'duplications',\n",
              " 'dux4',\n",
              " 'e1021k',\n",
              " 'e102_i103del',\n",
              " 'e1051k',\n",
              " 'e1060a',\n",
              " 'e106g',\n",
              " 'e1071w',\n",
              " 'e1099k',\n",
              " 'e116k',\n",
              " 'e120q',\n",
              " 'e1210k',\n",
              " 'e1214k',\n",
              " 'e124q',\n",
              " 'e1250k',\n",
              " 'e127g',\n",
              " 'e1282v',\n",
              " 'e1286v',\n",
              " 'e1322',\n",
              " 'e1346k',\n",
              " 'e1356g',\n",
              " 'e135k',\n",
              " 'e137k',\n",
              " 'e1384k',\n",
              " 'e139d',\n",
              " 'e14',\n",
              " 'e142d',\n",
              " 'e143k',\n",
              " 'e144k',\n",
              " 'e1552del',\n",
              " 'e157g',\n",
              " 'e1586g',\n",
              " 'e160',\n",
              " 'e161del',\n",
              " 'e1644g',\n",
              " 'e1660g',\n",
              " 'e1682k',\n",
              " 'e1682v',\n",
              " 'e168d',\n",
              " 'e1705a',\n",
              " 'e1705k',\n",
              " 'e172k',\n",
              " 'e1735k',\n",
              " 'e1794d',\n",
              " 'e1799k',\n",
              " 'e17k',\n",
              " 'e1836k',\n",
              " 'e190k',\n",
              " 'e1935g',\n",
              " 'e1978',\n",
              " 'e2014k',\n",
              " 'e203k',\n",
              " 'e207k',\n",
              " 'e218',\n",
              " 'e219k',\n",
              " 'e221q',\n",
              " 'e239a',\n",
              " 'e23fs',\n",
              " 'e2419k',\n",
              " 'e255k',\n",
              " 'e255v',\n",
              " 'e258v',\n",
              " 'e265k',\n",
              " 'e2663v',\n",
              " 'e267g',\n",
              " 'e275k',\n",
              " 'e279k',\n",
              " 'e281k',\n",
              " 'e2856a',\n",
              " 'e285k',\n",
              " 'e285v',\n",
              " 'e286k',\n",
              " 'e29v',\n",
              " 'e3002k',\n",
              " 'e311_k312del',\n",
              " 'e317k',\n",
              " 'e31k',\n",
              " 'e321g',\n",
              " 'e321k',\n",
              " 'e322k',\n",
              " 'e326l',\n",
              " 'e330g',\n",
              " 'e330k',\n",
              " 'e35',\n",
              " 'e355a',\n",
              " 'e362h',\n",
              " 'e365k',\n",
              " 'e380q',\n",
              " 'e40k',\n",
              " 'e40l',\n",
              " 'e40n',\n",
              " 'e40q',\n",
              " 'e40t',\n",
              " 'e40w',\n",
              " 'e41a',\n",
              " 'e439del',\n",
              " 'e452k',\n",
              " 'e453a',\n",
              " 'e459k',\n",
              " 'e462g',\n",
              " 'e466k',\n",
              " 'e475k',\n",
              " 'e483',\n",
              " 'e490k',\n",
              " 'e49k',\n",
              " 'e501g',\n",
              " 'e501k',\n",
              " 'e50k',\n",
              " 'e518a',\n",
              " 'e518k',\n",
              " 'e525k',\n",
              " 'e541k',\n",
              " 'e542g',\n",
              " 'e542k',\n",
              " 'e542q',\n",
              " 'e542v',\n",
              " 'e545a',\n",
              " 'e545g',\n",
              " 'e545k',\n",
              " 'e545q',\n",
              " 'e552k',\n",
              " 'e554_i571del',\n",
              " 'e554_k558del',\n",
              " 'e554_v559del',\n",
              " 'e563k',\n",
              " 'e565g',\n",
              " 'e571k',\n",
              " 'e579k',\n",
              " 'e580',\n",
              " 'e586k',\n",
              " 'e598_y599insdvdfreye',\n",
              " 'e598_y599insglvqvtgssdneyfyvdfreye',\n",
              " 'e5k',\n",
              " 'e606g',\n",
              " 'e60l',\n",
              " 'e612_f613insgyvdfreyeydlkwefrprenlef',\n",
              " 'e622d',\n",
              " 'e622q',\n",
              " 'e626k',\n",
              " 'e627d',\n",
              " 'e632_l633del',\n",
              " 'e633k',\n",
              " 'e636k',\n",
              " 'e664k',\n",
              " 'e685v',\n",
              " 'e69g',\n",
              " 'e69k',\n",
              " 'e709_t710delinsd',\n",
              " 'e709a',\n",
              " 'e709g',\n",
              " 'e709k',\n",
              " 'e709q',\n",
              " 'e709v',\n",
              " 'e70k',\n",
              " 'e717k',\n",
              " 'e719g',\n",
              " 'e719k',\n",
              " 'e731k',\n",
              " 'e734q',\n",
              " 'e746_a750del',\n",
              " 'e746_a750delinsq',\n",
              " 'e746_s752delinsa',\n",
              " 'e746_s752delinsi',\n",
              " 'e746_t751delinsa',\n",
              " 'e746_t751delinsva',\n",
              " 'e746_t751insip',\n",
              " 'e746g',\n",
              " 'e746q',\n",
              " 'e746v',\n",
              " 'e758g',\n",
              " 'e75g',\n",
              " 'e768d',\n",
              " 'e76a',\n",
              " 'e76k',\n",
              " 'e77k',\n",
              " 'e78k',\n",
              " 'e79k',\n",
              " 'e79q',\n",
              " 'e804g',\n",
              " 'e812k',\n",
              " 'e81k',\n",
              " 'e82d',\n",
              " 'e82g',\n",
              " 'e82v',\n",
              " 'e836k',\n",
              " 'e839k',\n",
              " 'e846k',\n",
              " 'e866k',\n",
              " 'e868g',\n",
              " 'e872k',\n",
              " 'e875g',\n",
              " 'e884k',\n",
              " 'e88k',\n",
              " 'e921k',\n",
              " 'e946',\n",
              " 'e996k',\n",
              " 'ebf1',\n",
              " 'egfr',\n",
              " 'egfrvii',\n",
              " 'egfrviii',\n",
              " 'egfrviv',\n",
              " 'egfrvv',\n",
              " 'ep300',\n",
              " 'epigenetic',\n",
              " 'erbb4',\n",
              " 'erg',\n",
              " 'erlin2',\n",
              " 'esr1',\n",
              " 'esrp1',\n",
              " 'etv1',\n",
              " 'etv4',\n",
              " 'etv5',\n",
              " 'etv6',\n",
              " 'evi1',\n",
              " 'ewsr1',\n",
              " 'exon',\n",
              " 'ezr',\n",
              " 'f102c',\n",
              " 'f1061w',\n",
              " 'f1088lfs',\n",
              " 'f1088sfs',\n",
              " 'f1174i',\n",
              " 'f1174l',\n",
              " 'f119s',\n",
              " 'f1200i',\n",
              " 'f123i',\n",
              " 'f1245c',\n",
              " 'f1245v',\n",
              " 'f129l',\n",
              " 'f12l',\n",
              " 'f133l',\n",
              " 'f133v',\n",
              " 'f134y',\n",
              " 'f1524v',\n",
              " 'f154l',\n",
              " 'f156l',\n",
              " 'f158c',\n",
              " 'f1592s',\n",
              " 'f161l',\n",
              " 'f1662s',\n",
              " 'f1695l',\n",
              " 'f1704s',\n",
              " 'f170i',\n",
              " 'f1734s',\n",
              " 'f1761i',\n",
              " 'f1761s',\n",
              " 'f1888i',\n",
              " 'f1888l',\n",
              " 'f1888v',\n",
              " 'f2108l',\n",
              " 'f212y',\n",
              " 'f21a',\n",
              " 'f241s',\n",
              " 'f248s',\n",
              " 'f28l',\n",
              " 'f311l',\n",
              " 'f317l',\n",
              " 'f31i',\n",
              " 'f328v',\n",
              " 'f341c',\n",
              " 'f341v',\n",
              " 'f346v',\n",
              " 'f347l',\n",
              " 'f351l',\n",
              " 'f354l',\n",
              " 'f359c',\n",
              " 'f367s',\n",
              " 'f384l',\n",
              " 'f384v',\n",
              " 'f384y',\n",
              " 'f400i',\n",
              " 'f460l',\n",
              " 'f468c',\n",
              " 'f522c',\n",
              " 'f537_k539delinsl',\n",
              " 'f53c',\n",
              " 'f53l',\n",
              " 'f53s',\n",
              " 'f568fs',\n",
              " 'f57c',\n",
              " 'f57l',\n",
              " 'f57v',\n",
              " 'f590g',\n",
              " 'f594_r595inssdneyfyvdf',\n",
              " 'f594l',\n",
              " 'f615s',\n",
              " 'f691l',\n",
              " 'f71i',\n",
              " 'f74s',\n",
              " 'f79s',\n",
              " 'f808l',\n",
              " 'f81v',\n",
              " 'f876l',\n",
              " 'f877l',\n",
              " 'f893l',\n",
              " 'f958s',\n",
              " 'f958v',\n",
              " 'fam118b',\n",
              " 'fam131b',\n",
              " 'fam76a',\n",
              " 'fev',\n",
              " 'fgfr1',\n",
              " 'fgfr1op1',\n",
              " 'fgfr2',\n",
              " 'fgfr3',\n",
              " 'fig',\n",
              " 'fli1',\n",
              " 'flt3',\n",
              " 'fus',\n",
              " 'fusion',\n",
              " 'fusions',\n",
              " 'g101s',\n",
              " 'g101w',\n",
              " 'g1035s',\n",
              " 'g106_r108del',\n",
              " 'g106d',\n",
              " 'g106v',\n",
              " 'g1079d',\n",
              " 'g1123d',\n",
              " 'g1123s',\n",
              " 'g1125a',\n",
              " 'g1128a',\n",
              " 'g1128s',\n",
              " 'g114r',\n",
              " 'g116s',\n",
              " 'g118d',\n",
              " 'g1194d',\n",
              " 'g1201e',\n",
              " 'g1202r',\n",
              " 'g1232d',\n",
              " 'g123r',\n",
              " 'g123s',\n",
              " 'g1269a',\n",
              " 'g1269s',\n",
              " 'g127e',\n",
              " 'g127n',\n",
              " 'g1286r',\n",
              " 'g128v',\n",
              " 'g129a',\n",
              " 'g129e',\n",
              " 'g129r',\n",
              " 'g12a',\n",
              " 'g12c',\n",
              " 'g12d',\n",
              " 'g12f',\n",
              " 'g12r',\n",
              " 'g12s',\n",
              " 'g12v',\n",
              " 'g13c',\n",
              " 'g13d',\n",
              " 'g13e',\n",
              " 'g13r',\n",
              " 'g13v',\n",
              " 'g14v',\n",
              " 'g1529r',\n",
              " 'g1567d',\n",
              " 'g1596v',\n",
              " 'g161v',\n",
              " 'g163d',\n",
              " 'g1656d',\n",
              " 'g165e',\n",
              " 'g165r',\n",
              " 'g165v',\n",
              " 'g1706a',\n",
              " 'g1706e',\n",
              " 'g1738e',\n",
              " 'g1738r',\n",
              " 'g1743r',\n",
              " 'g1763v',\n",
              " 'g1770v',\n",
              " 'g1788d',\n",
              " 'g1788v',\n",
              " 'g17a',\n",
              " 'g17e',\n",
              " 'g17v',\n",
              " 'g1803a',\n",
              " 'g1809k',\n",
              " 'g1809r',\n",
              " 'g186r',\n",
              " 'g1971e',\n",
              " 'g199r',\n",
              " 'g2032r',\n",
              " 'g207e',\n",
              " 'g20e',\n",
              " 'g2101a',\n",
              " 'g216r',\n",
              " 'g2274v',\n",
              " 'g23d',\n",
              " 'g2430a',\n",
              " 'g244d',\n",
              " 'g244r',\n",
              " 'g244s',\n",
              " 'g245a',\n",
              " 'g245d',\n",
              " 'g245s',\n",
              " 'g248v',\n",
              " 'g250e',\n",
              " 'g251c',\n",
              " 'g253c',\n",
              " 'g264s',\n",
              " 'g266e',\n",
              " 'g266r',\n",
              " 'g271e',\n",
              " 'g2748d',\n",
              " 'g284r',\n",
              " 'g305r',\n",
              " 'g305w',\n",
              " 'g309a',\n",
              " 'g309e',\n",
              " 'g311d',\n",
              " 'g31a',\n",
              " 'g31r',\n",
              " 'g31v',\n",
              " 'g322s',\n",
              " 'g325a',\n",
              " 'g325r',\n",
              " 'g328e',\n",
              " 'g328v',\n",
              " 'g333s',\n",
              " 'g334r',\n",
              " 'g34e',\n",
              " 'g34v',\n",
              " 'g356a',\n",
              " 'g35a',\n",
              " 'g35r',\n",
              " 'g35v',\n",
              " 'g370c',\n",
              " 'g373r',\n",
              " 'g375c',\n",
              " 'g375p',\n",
              " 'g376r',\n",
              " 'g380r',\n",
              " 'g382d',\n",
              " 'g39e',\n",
              " 'g419v',\n",
              " 'g423r',\n",
              " 'g423v',\n",
              " 'g42r',\n",
              " 'g430c',\n",
              " 'g434r',\n",
              " 'g44s',\n",
              " 'g464a',\n",
              " 'g464e',\n",
              " 'g464r',\n",
              " 'g464v',\n",
              " 'g465e',\n",
              " 'g466a',\n",
              " 'g466e',\n",
              " 'g466r',\n",
              " 'g466v',\n",
              " 'g469a',\n",
              " 'g469del',\n",
              " 'g469e',\n",
              " 'g469v',\n",
              " 'g478c',\n",
              " 'g480w',\n",
              " 'g503v',\n",
              " 'g505s',\n",
              " 'g508s',\n",
              " 'g52r',\n",
              " 'g591v',\n",
              " 'g596c',\n",
              " 'g596r',\n",
              " 'g596v',\n",
              " 'g602r',\n",
              " 'g60d',\n",
              " 'g60e',\n",
              " 'g60r',\n",
              " 'g623r',\n",
              " 'g637w',\n",
              " 'g660d',\n",
              " 'g665a',\n",
              " 'g67r',\n",
              " 'g67s',\n",
              " 'g67w',\n",
              " 'g697c',\n",
              " 'g701s',\n",
              " 'g70d',\n",
              " 'g719a',\n",
              " 'g719c',\n",
              " 'g719d',\n",
              " 'g719s',\n",
              " 'g724s',\n",
              " 'g735s',\n",
              " 'g751r',\n",
              " 'g75r',\n",
              " 'g774v',\n",
              " 'g776_v777insyvma',\n",
              " 'g776delinslc',\n",
              " 'g776delinsvc',\n",
              " 'g776s',\n",
              " 'g778_p780dup',\n",
              " 'g785s',\n",
              " 'g796s',\n",
              " 'g810s',\n",
              " 'g81d',\n",
              " 'g81r',\n",
              " 'g81s',\n",
              " 'g829r',\n",
              " 'g831e',\n",
              " 'g853d',\n",
              " 'g857a',\n",
              " 'g857e',\n",
              " 'g85r',\n",
              " 'g863d',\n",
              " 'g863s',\n",
              " 'g87r',\n",
              " 'g881d',\n",
              " 'g909r',\n",
              " 'g914r',\n",
              " 'g936r',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2F0uxIrrj7P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6a83a18d-a7c9-476a-c9cb-9042f7eb86a7"
      },
      "source": [
        "#We can still do some processing here by removing stop words,features that occurs less than 3 times and setting the maximum features to 5000\n",
        "vectorizer = TfidfVectorizer(stop_words='english',min_df=3)\n",
        "vecTEXT= vectorizer.fit_transform(result_data.TEXT)\n",
        "#Checking data shape\n",
        "print(vecTEXT.shape)\n",
        "# checking the Column \n",
        "vectorizer.get_feature_names()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3321, 43793)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['00',\n",
              " '000',\n",
              " '0000',\n",
              " '0000001',\n",
              " '000002',\n",
              " '000007',\n",
              " '00001',\n",
              " '00002644',\n",
              " '00005',\n",
              " '00009',\n",
              " '0001',\n",
              " '00016',\n",
              " '000182',\n",
              " '00019',\n",
              " '0001a',\n",
              " '0002',\n",
              " '0002158',\n",
              " '000245',\n",
              " '00029',\n",
              " '0003',\n",
              " '000357129',\n",
              " '0004',\n",
              " '0005',\n",
              " '0006',\n",
              " '0007',\n",
              " '0008',\n",
              " '00088',\n",
              " '0009',\n",
              " '000g',\n",
              " '000xg',\n",
              " '001',\n",
              " '00103',\n",
              " '0011',\n",
              " '001100',\n",
              " '001105',\n",
              " '0012',\n",
              " '001210',\n",
              " '0012a',\n",
              " '0013',\n",
              " '0014',\n",
              " '0014b',\n",
              " '0015',\n",
              " '0016',\n",
              " '00161',\n",
              " '0017',\n",
              " '0018',\n",
              " '001810',\n",
              " '0019',\n",
              " '001a',\n",
              " '001acd4',\n",
              " '001acd8',\n",
              " '001bathe',\n",
              " '001bimmunophenotypecd34',\n",
              " '001blyl1',\n",
              " '002',\n",
              " '0021',\n",
              " '0022',\n",
              " '0023',\n",
              " '0024',\n",
              " '0025',\n",
              " '0025021',\n",
              " '0026',\n",
              " '0026a',\n",
              " '0027',\n",
              " '0028',\n",
              " '00299804',\n",
              " '002a',\n",
              " '003',\n",
              " '0030',\n",
              " '003008',\n",
              " '0030485',\n",
              " '0031',\n",
              " '003133',\n",
              " '0032',\n",
              " '0032555',\n",
              " '0032a',\n",
              " '0033',\n",
              " '003333',\n",
              " '0034',\n",
              " '0035',\n",
              " '0036',\n",
              " '0037',\n",
              " '0038',\n",
              " '0039',\n",
              " '003a',\n",
              " '004',\n",
              " '0040',\n",
              " '0041',\n",
              " '0043',\n",
              " '0044',\n",
              " '004448',\n",
              " '0045',\n",
              " '0047',\n",
              " '0048',\n",
              " '005',\n",
              " '005045',\n",
              " '005228',\n",
              " '0055',\n",
              " '0055b',\n",
              " '005771',\n",
              " '0059a',\n",
              " '006',\n",
              " '0063',\n",
              " '0065',\n",
              " '0068',\n",
              " '0069',\n",
              " '006a',\n",
              " '006acd1',\n",
              " '007',\n",
              " '0071',\n",
              " '0075',\n",
              " '0076',\n",
              " '0078',\n",
              " '00782',\n",
              " '0079',\n",
              " '008',\n",
              " '008461',\n",
              " '0085',\n",
              " '0086c',\n",
              " '00882',\n",
              " '0089',\n",
              " '008968',\n",
              " '00897702',\n",
              " '008acd3',\n",
              " '009',\n",
              " '0091',\n",
              " '00949',\n",
              " '00kb',\n",
              " '01',\n",
              " '010',\n",
              " '0103',\n",
              " '011',\n",
              " '0113',\n",
              " '01151',\n",
              " '01165',\n",
              " '012',\n",
              " '01223',\n",
              " '012325',\n",
              " '01249',\n",
              " '01261',\n",
              " '0127',\n",
              " '013',\n",
              " '0132',\n",
              " '0134',\n",
              " '013b',\n",
              " '014',\n",
              " '0147',\n",
              " '015',\n",
              " '01548',\n",
              " '0157',\n",
              " '016',\n",
              " '0165',\n",
              " '0167',\n",
              " '0169',\n",
              " '017',\n",
              " '0172',\n",
              " '0175',\n",
              " '01787',\n",
              " '01798',\n",
              " '017b',\n",
              " '018',\n",
              " '0182',\n",
              " '0186',\n",
              " '018664',\n",
              " '01881',\n",
              " '019',\n",
              " '02',\n",
              " '020',\n",
              " '0201',\n",
              " '0207',\n",
              " '0208',\n",
              " '020a',\n",
              " '020b',\n",
              " '021',\n",
              " '02114',\n",
              " '02115',\n",
              " '0212',\n",
              " '02129',\n",
              " '02139',\n",
              " '02179',\n",
              " '022',\n",
              " '0221',\n",
              " '0222',\n",
              " '02255',\n",
              " '02285',\n",
              " '023',\n",
              " '02341066',\n",
              " '024',\n",
              " '0246',\n",
              " '0247',\n",
              " '02491',\n",
              " '024zd',\n",
              " '025',\n",
              " '0250',\n",
              " '026',\n",
              " '0264488362',\n",
              " '0264488363',\n",
              " '027',\n",
              " '0279',\n",
              " '028',\n",
              " '0288',\n",
              " '029',\n",
              " '02911',\n",
              " '02a',\n",
              " '02b',\n",
              " '02b90',\n",
              " '03',\n",
              " '030',\n",
              " '0309',\n",
              " '031',\n",
              " '0312',\n",
              " '0314',\n",
              " '0318',\n",
              " '032',\n",
              " '0325901',\n",
              " '033',\n",
              " '0332991',\n",
              " '034',\n",
              " '03473',\n",
              " '035',\n",
              " '0356',\n",
              " '036',\n",
              " '03651',\n",
              " '0368',\n",
              " '037',\n",
              " '03751',\n",
              " '038',\n",
              " '039',\n",
              " '0392',\n",
              " '03a',\n",
              " '03e',\n",
              " '04',\n",
              " '040',\n",
              " '0405',\n",
              " '041',\n",
              " '04105',\n",
              " '042',\n",
              " '04217903',\n",
              " '043',\n",
              " '0432',\n",
              " '0433',\n",
              " '044',\n",
              " '045',\n",
              " '0457',\n",
              " '04576',\n",
              " '045a',\n",
              " '046',\n",
              " '0464',\n",
              " '046acd13',\n",
              " '047',\n",
              " '04739',\n",
              " '048',\n",
              " '049',\n",
              " '0495',\n",
              " '0498',\n",
              " '05',\n",
              " '050',\n",
              " '05079a02',\n",
              " '051',\n",
              " '0513',\n",
              " '0516',\n",
              " '052',\n",
              " '053',\n",
              " '054',\n",
              " '055',\n",
              " '056',\n",
              " '057',\n",
              " '058',\n",
              " '059',\n",
              " '05a',\n",
              " '06',\n",
              " '060',\n",
              " '0602',\n",
              " '0609',\n",
              " '061',\n",
              " '0615b',\n",
              " '062',\n",
              " '0625',\n",
              " '063',\n",
              " '064',\n",
              " '06439015',\n",
              " '0646392',\n",
              " '06463922',\n",
              " '06469322',\n",
              " '065',\n",
              " '066',\n",
              " '0660',\n",
              " '067',\n",
              " '06797',\n",
              " '068',\n",
              " '0686',\n",
              " '069',\n",
              " '06Ã¥',\n",
              " '07',\n",
              " '070',\n",
              " '0709',\n",
              " '071',\n",
              " '07159',\n",
              " '072',\n",
              " '073',\n",
              " '074',\n",
              " '075',\n",
              " '076',\n",
              " '077',\n",
              " '078',\n",
              " '079',\n",
              " '08',\n",
              " '080',\n",
              " '0802655105',\n",
              " '080a',\n",
              " '081',\n",
              " '0810',\n",
              " '082',\n",
              " '083',\n",
              " '084',\n",
              " '085',\n",
              " '08548',\n",
              " '086',\n",
              " '087',\n",
              " '088',\n",
              " '089',\n",
              " '08e',\n",
              " '08plusminus0',\n",
              " '08Ã¥',\n",
              " '09',\n",
              " '090',\n",
              " '091',\n",
              " '0910',\n",
              " '0917',\n",
              " '092',\n",
              " '093',\n",
              " '094',\n",
              " '0941',\n",
              " '095',\n",
              " '0950',\n",
              " '096',\n",
              " '097',\n",
              " '09735',\n",
              " '098',\n",
              " '0980',\n",
              " '099',\n",
              " '0996',\n",
              " '0b',\n",
              " '0c',\n",
              " '0e',\n",
              " '0f',\n",
              " '0h',\n",
              " '0months',\n",
              " '0nm',\n",
              " '0r',\n",
              " '0x',\n",
              " '0Ã¥',\n",
              " '10',\n",
              " '100',\n",
              " '1000',\n",
              " '10000',\n",
              " '1000genomes',\n",
              " '1000Î¼g',\n",
              " '1001',\n",
              " '10016',\n",
              " '1002',\n",
              " '1003',\n",
              " '1003545',\n",
              " '1004',\n",
              " '1005',\n",
              " '1006',\n",
              " '1007',\n",
              " '1008',\n",
              " '1009',\n",
              " '100908',\n",
              " '100bp',\n",
              " '100k',\n",
              " '100m',\n",
              " '100mg',\n",
              " '100mm',\n",
              " '100mm3',\n",
              " '100ng',\n",
              " '100nm',\n",
              " '100o5',\n",
              " '100ug',\n",
              " '100x',\n",
              " '100Âµg',\n",
              " '100Î¼m',\n",
              " '101',\n",
              " '1010',\n",
              " '1011',\n",
              " '1012',\n",
              " '10138',\n",
              " '1014',\n",
              " '1016',\n",
              " '101r',\n",
              " '102',\n",
              " '1020',\n",
              " '1021',\n",
              " '1022',\n",
              " '1023',\n",
              " '1024',\n",
              " '10249',\n",
              " '1028',\n",
              " '102k',\n",
              " '103',\n",
              " '1030',\n",
              " '1032',\n",
              " '1033',\n",
              " '1034',\n",
              " '1035',\n",
              " '1036c2',\n",
              " '1037',\n",
              " '1037delc',\n",
              " '1038',\n",
              " '1039',\n",
              " '103g',\n",
              " '103k',\n",
              " '104',\n",
              " '1040',\n",
              " '10411',\n",
              " '10417',\n",
              " '1042',\n",
              " '1043',\n",
              " '104403',\n",
              " '1045',\n",
              " '1046',\n",
              " '1047',\n",
              " '1048',\n",
              " '1049',\n",
              " '104c',\n",
              " '104g4c',\n",
              " '104g4t',\n",
              " '104k',\n",
              " '105',\n",
              " '1050',\n",
              " '105010',\n",
              " '1051',\n",
              " '1052g',\n",
              " '1056',\n",
              " '1057',\n",
              " '1059',\n",
              " '1059_1062del',\n",
              " '105k',\n",
              " '106',\n",
              " '1061',\n",
              " '1062',\n",
              " '1063',\n",
              " '1064',\n",
              " '1064p9',\n",
              " '1066',\n",
              " '1067',\n",
              " '1068',\n",
              " '1069',\n",
              " '106nm',\n",
              " '106th',\n",
              " '107',\n",
              " '10704',\n",
              " '1071',\n",
              " '10710',\n",
              " '1072',\n",
              " '1073',\n",
              " '1076',\n",
              " '10770',\n",
              " '1078',\n",
              " '10789',\n",
              " '108',\n",
              " '1080',\n",
              " '1081',\n",
              " '1081c',\n",
              " '1082',\n",
              " '10838',\n",
              " '1084',\n",
              " '1085',\n",
              " '1086',\n",
              " '1087',\n",
              " '1088',\n",
              " '1089',\n",
              " '108d2',\n",
              " '109',\n",
              " '1090',\n",
              " '1092',\n",
              " '1093',\n",
              " '1094',\n",
              " '1096',\n",
              " '10969',\n",
              " '1099',\n",
              " '1099x',\n",
              " '10a',\n",
              " '10b',\n",
              " '10bp',\n",
              " '10c',\n",
              " '10d',\n",
              " '10division',\n",
              " '10e',\n",
              " '10e9',\n",
              " '10gy',\n",
              " '10min',\n",
              " '10ml',\n",
              " '10mm',\n",
              " '10n',\n",
              " '10ng',\n",
              " '10nm',\n",
              " '10p',\n",
              " '10p11',\n",
              " '10p12',\n",
              " '10q',\n",
              " '10q21',\n",
              " '10q22',\n",
              " '10q23',\n",
              " '10q26',\n",
              " '10r',\n",
              " '10s',\n",
              " '10st',\n",
              " '10th',\n",
              " '10ug',\n",
              " '10x',\n",
              " '10Î¼g',\n",
              " '10Î¼l',\n",
              " '10Î¼m',\n",
              " '11',\n",
              " '110',\n",
              " '1100',\n",
              " '1100delc',\n",
              " '1101',\n",
              " '1103',\n",
              " '1104',\n",
              " '1105',\n",
              " '1106',\n",
              " '1107',\n",
              " '1108',\n",
              " '110Î±',\n",
              " '111',\n",
              " '1110',\n",
              " '1111',\n",
              " '1112',\n",
              " '11128',\n",
              " '1114',\n",
              " '1116',\n",
              " '1118',\n",
              " '112',\n",
              " '1120',\n",
              " '1123',\n",
              " '1124',\n",
              " '1125',\n",
              " '1126',\n",
              " '1128',\n",
              " '1129',\n",
              " '113',\n",
              " '1130',\n",
              " '1131',\n",
              " '1134',\n",
              " '1136',\n",
              " '1137',\n",
              " '113705',\n",
              " '1138',\n",
              " '11384',\n",
              " '1139',\n",
              " '1139t',\n",
              " '114',\n",
              " '1143',\n",
              " '1144',\n",
              " '114500',\n",
              " '1149',\n",
              " '115',\n",
              " '1150',\n",
              " '1151',\n",
              " '115150',\n",
              " '1151t',\n",
              " '1151tins',\n",
              " '1152',\n",
              " '1153',\n",
              " '1153_1253del',\n",
              " '1156',\n",
              " '1158',\n",
              " '1159',\n",
              " '115k',\n",
              " '116',\n",
              " '1162',\n",
              " '1162c',\n",
              " '11644807001',\n",
              " '1166',\n",
              " '1167',\n",
              " '11691112001',\n",
              " '116aa',\n",
              " '116k',\n",
              " '117',\n",
              " '1172',\n",
              " '1172t',\n",
              " '1173',\n",
              " '1174',\n",
              " '117456',\n",
              " '117550',\n",
              " '1176',\n",
              " '1177',\n",
              " '1179',\n",
              " '117o13',\n",
              " '118',\n",
              " '1180',\n",
              " '1182',\n",
              " '1185',\n",
              " '1186',\n",
              " '1187',\n",
              " '1188',\n",
              " '118c',\n",
              " '118k',\n",
              " '118mg',\n",
              " '118p',\n",
              " '119',\n",
              " '1191',\n",
              " '1192',\n",
              " '1193',\n",
              " '1193g',\n",
              " '1196',\n",
              " '1197',\n",
              " '1198',\n",
              " '119804',\n",
              " '11a',\n",
              " '11b',\n",
              " '11c',\n",
              " '11d',\n",
              " '11department',\n",
              " '11division',\n",
              " '11e',\n",
              " '11e12',\n",
              " '11p',\n",
              " '11p13',\n",
              " '11p15',\n",
              " '11q',\n",
              " '11q12',\n",
              " '11q13',\n",
              " '11q14',\n",
              " '11q22',\n",
              " '11q23',\n",
              " '11q24',\n",
              " '11r',\n",
              " '11th',\n",
              " '12',\n",
              " '120',\n",
              " '1200',\n",
              " '1201',\n",
              " '1202',\n",
              " '120435',\n",
              " '120436',\n",
              " '1204g',\n",
              " '1205',\n",
              " '1206',\n",
              " '12063',\n",
              " '1207',\n",
              " '1209',\n",
              " '120k',\n",
              " '120ra17',\n",
              " '121',\n",
              " '1210',\n",
              " '121106',\n",
              " '1213',\n",
              " '1214',\n",
              " '1217',\n",
              " '122',\n",
              " '1221',\n",
              " '1222',\n",
              " '1225',\n",
              " '12252',\n",
              " '1226',\n",
              " '1228',\n",
              " '1229',\n",
              " '122g',\n",
              " '123',\n",
              " '1230',\n",
              " '1231',\n",
              " '1232',\n",
              " '1233',\n",
              " '1234',\n",
              " '123456',\n",
              " '1235',\n",
              " '1239',\n",
              " '123i',\n",
              " '124',\n",
              " '1240',\n",
              " '1240c',\n",
              " '1240x',\n",
              " '1241',\n",
              " '1243',\n",
              " '1244',\n",
              " '1244_7delacag',\n",
              " '1245',\n",
              " '1247',\n",
              " '12477',\n",
              " '1248',\n",
              " '1249',\n",
              " '1249c',\n",
              " '124c',\n",
              " '124k',\n",
              " '125',\n",
              " '1250',\n",
              " '1250c',\n",
              " '1251',\n",
              " '1252',\n",
              " '1252a',\n",
              " '1253',\n",
              " '1255',\n",
              " '1257',\n",
              " '125a',\n",
              " '125b',\n",
              " '125i',\n",
              " '126',\n",
              " '1261',\n",
              " '1262',\n",
              " '1264',\n",
              " '12670',\n",
              " '1268',\n",
              " '1269',\n",
              " '126c',\n",
              " '127',\n",
              " '1270',\n",
              " '1271',\n",
              " '1272',\n",
              " '12721',\n",
              " '1275',\n",
              " '1276',\n",
              " '1277',\n",
              " '1278',\n",
              " '127k',\n",
              " '128',\n",
              " '1280',\n",
              " '1281',\n",
              " '1281c',\n",
              " '1282',\n",
              " '12826z',\n",
              " '1283',\n",
              " '12844c',\n",
              " '1287',\n",
              " '1289',\n",
              " '128delv',\n",
              " '128k',\n",
              " '128kb',\n",
              " '129',\n",
              " '12911',\n",
              " '1292',\n",
              " '1292a',\n",
              " '1294',\n",
              " '1295',\n",
              " '1298',\n",
              " '129sv',\n",
              " '12a',\n",
              " '12b',\n",
              " '12bp',\n",
              " '12c',\n",
              " '12ca5',\n",
              " '12d',\n",
              " '12department',\n",
              " '12e',\n",
              " '12e1b',\n",
              " '12h',\n",
              " '12mm',\n",
              " '12munich',\n",
              " '12nm',\n",
              " '12p',\n",
              " '12p11',\n",
              " '12p12',\n",
              " '12p13',\n",
              " '12q',\n",
              " '12q12',\n",
              " '12q13',\n",
              " '12q14',\n",
              " '12q15',\n",
              " '12q24',\n",
              " '12r',\n",
              " '12th',\n",
              " '12v',\n",
              " '12v4',\n",
              " '12xcsl',\n",
              " '13',\n",
              " '130',\n",
              " '1300',\n",
              " '13000',\n",
              " '13008',\n",
              " '1301',\n",
              " '13057',\n",
              " '13058',\n",
              " '13059',\n",
              " '13060',\n",
              " '13061',\n",
              " '13062',\n",
              " '130k',\n",
              " '131',\n",
              " '1315',\n",
              " '131550',\n",
              " '132',\n",
              " '1322r',\n",
              " '1324',\n",
              " '1326',\n",
              " '1327',\n",
              " '1328',\n",
              " '133',\n",
              " '1330',\n",
              " '1331',\n",
              " '1333',\n",
              " '1333r',\n",
              " '1334',\n",
              " '1335',\n",
              " '133520',\n",
              " '1336',\n",
              " '1337',\n",
              " '1338y',\n",
              " '134',\n",
              " '1340',\n",
              " '1343_65del22',\n",
              " '1345',\n",
              " '1347',\n",
              " '1349',\n",
              " '134a',\n",
              " '134k',\n",
              " '134vi',\n",
              " '135',\n",
              " '1350',\n",
              " '1353',\n",
              " '1355',\n",
              " '1356',\n",
              " '135651',\n",
              " '13593',\n",
              " '135insa',\n",
              " '136',\n",
              " '1360',\n",
              " '13601a02',\n",
              " '1365',\n",
              " '1367',\n",
              " '136k',\n",
              " '137',\n",
              " '1370',\n",
              " '1371',\n",
              " '1372',\n",
              " '1373',\n",
              " '1375',\n",
              " '1376',\n",
              " '1377',\n",
              " '138',\n",
              " '1381c',\n",
              " '1383',\n",
              " '1384',\n",
              " '1387',\n",
              " '1389',\n",
              " '139',\n",
              " '1390',\n",
              " '1392',\n",
              " '1393',\n",
              " '1393g',\n",
              " '1397',\n",
              " '1398',\n",
              " '1399',\n",
              " '13999',\n",
              " '139c',\n",
              " '13a',\n",
              " '13b',\n",
              " '13c',\n",
              " '13c6',\n",
              " '13c9',\n",
              " '13cÎ±',\n",
              " '13cÎ²',\n",
              " '13department',\n",
              " '13hematology',\n",
              " '13i6',\n",
              " '13mp2',\n",
              " '13q',\n",
              " '13q11',\n",
              " '13q12',\n",
              " '13q14',\n",
              " '13th',\n",
              " '14',\n",
              " '140',\n",
              " '1400',\n",
              " '1401',\n",
              " '14024',\n",
              " '1403',\n",
              " '1404',\n",
              " '1405',\n",
              " '141',\n",
              " '1410',\n",
              " '1416',\n",
              " '1417',\n",
              " '1419',\n",
              " '142',\n",
              " '1420',\n",
              " '1421',\n",
              " '142168344',\n",
              " '142172070',\n",
              " '1423',\n",
              " '1425',\n",
              " '14252',\n",
              " '1427',\n",
              " '143',\n",
              " '14302z',\n",
              " '1431',\n",
              " '1434c',\n",
              " '1437',\n",
              " '1439c',\n",
              " '143a',\n",
              " '143k',\n",
              " '144',\n",
              " '1440',\n",
              " '1441',\n",
              " '1442',\n",
              " '1446',\n",
              " '1447',\n",
              " '144700',\n",
              " '144p',\n",
              " '145',\n",
              " '1450',\n",
              " '1451',\n",
              " '1455',\n",
              " '1459',\n",
              " '145k',\n",
              " '146',\n",
              " '146000',\n",
              " '14643',\n",
              " '14644',\n",
              " '1464stop',\n",
              " '1468',\n",
              " '1469',\n",
              " '146a',\n",
              " '146c',\n",
              " '146k',\n",
              " '147',\n",
              " '1470',\n",
              " '1471',\n",
              " '14725',\n",
              " '1475',\n",
              " '1476',\n",
              " '1477c',\n",
              " '14784',\n",
              " '147920',\n",
              " '147a',\n",
              " '147k',\n",
              " '148',\n",
              " '1483',\n",
              " '1484_1488delctcaa',\n",
              " '148k',\n",
              " '149',\n",
              " '1492',\n",
              " '1494',\n",
              " '1495',\n",
              " '1497',\n",
              " '149730',\n",
              " '1498',\n",
              " '14a',\n",
              " '14b',\n",
              " '14c',\n",
              " '14d',\n",
              " '14department',\n",
              " '14national',\n",
              " '14q',\n",
              " '14q13',\n",
              " '14q21',\n",
              " '14q24',\n",
              " '14q32',\n",
              " '14resource',\n",
              " '14th',\n",
              " '15',\n",
              " '150',\n",
              " '1500',\n",
              " '15000',\n",
              " '150007',\n",
              " '1500mm3',\n",
              " '1503',\n",
              " '1509',\n",
              " '150i',\n",
              " '150mg',\n",
              " '150mm',\n",
              " '150nm',\n",
              " '150v',\n",
              " '151',\n",
              " '1513',\n",
              " '15138z',\n",
              " '15149',\n",
              " '1514g',\n",
              " '151623',\n",
              " '15187',\n",
              " '1519',\n",
              " '1519c',\n",
              " '1519gc',\n",
              " '151k',\n",
              " '152',\n",
              " '1520',\n",
              " '1522',\n",
              " '1524',\n",
              " '1525',\n",
              " '1525t',\n",
              " '1526g',\n",
              " '1529',\n",
              " '153',\n",
              " '1530',\n",
              " '1532',\n",
              " '1534',\n",
              " '1535',\n",
              " '1536',\n",
              " '153k',\n",
              " '154',\n",
              " '1541',\n",
              " '1544',\n",
              " '154769',\n",
              " '1548',\n",
              " '154838u22',\n",
              " '154899u20',\n",
              " '154g',\n",
              " '155',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP3eXkjcrj7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#combing all features using hstack and compresing using compressed sparse row format\n",
        "result=hstack([vecGene, vecVariation,vecTEXT]).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn7rxW9arj7g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3fe89af5-00ff-4b8a-8c28-1d55bd0fe190"
      },
      "source": [
        "# setting the y_true\n",
        "y =np.array(result_data['Class'].values)\n",
        "#Checking what type of data we have in our Class column\n",
        "result_data['Class'].unique()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx7Ijdiwrj7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spliting data into test and trainning\n",
        "X_train, X_test, y_train, y_test = train_test_split(result, y, test_size=0.2, random_state=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo97WJARrj7s",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning\n",
        "\n",
        "we will try a series of algorithms to get the best performer.\n",
        "- Naive Baise\n",
        "- KNearest Neigbor\n",
        "- SGD\n",
        "- SVM\n",
        "- Random Forest\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ9PCi36rj7u",
        "colab_type": "text"
      },
      "source": [
        "## Naive Biase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orEEftqkrj7w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "45caf6fc-208d-4d18-e8ad-05ef3221f5a5"
      },
      "source": [
        "#MultinomialNB\n",
        "model = MultinomialNB()\n",
        "alphas = [1.e-10,1.e-5, 1.e-3,1.e-1,0.1, 0.5, 1]\n",
        "grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas),cv=3)\n",
        "grid.fit(X_train, y_train)\n",
        "print(grid)\n",
        "#result summary\n",
        "print(grid.best_score_)\n",
        "print(grid.best_estimator_.alpha)\n",
        "\n",
        " "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
            "             estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
            "                                     fit_prior=True),\n",
            "             iid='warn', n_jobs=None,\n",
            "             param_grid={'alpha': [1e-10, 1e-05, 0.001, 0.1, 0.1, 0.5, 1]},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=None, verbose=0)\n",
            "0.5926204819277109\n",
            "0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0vsTKbBrj79",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "97430ea3-dd24-438a-a9a7-a0a18b202faa"
      },
      "source": [
        "#predicting using best alpha\n",
        "alpha=grid.best_estimator_.alpha\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred=model.predict(X_test)\n",
        "score=accuracy_score(y_test,y_pred)\n",
        "print(score)\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5984962406015037\n",
            "[[ 64   1   0  20  14   3   1   0   0]\n",
            " [  0  23   0   2   0   1  66   0   0]\n",
            " [  2   0   0   7   4   0  11   0   0]\n",
            " [ 27   1   0 102   7   1   6   0   0]\n",
            " [  8   0   0  11  21   6  14   0   0]\n",
            " [  5   1   0   4  10  15  16   0   0]\n",
            " [  2   5   0   3   0   0 173   0   0]\n",
            " [  0   0   0   2   0   0   0   0   0]\n",
            " [  0   0   0   3   0   0   3   0   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.59      0.62      0.61       103\n",
            "           2       0.74      0.25      0.37        92\n",
            "           3       0.00      0.00      0.00        24\n",
            "           4       0.66      0.71      0.68       144\n",
            "           5       0.38      0.35      0.36        60\n",
            "           6       0.58      0.29      0.39        51\n",
            "           7       0.60      0.95      0.73       183\n",
            "           8       0.00      0.00      0.00         2\n",
            "           9       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.60       665\n",
            "   macro avg       0.39      0.35      0.35       665\n",
            "weighted avg       0.58      0.60      0.56       665\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEMcD1r0rj8E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3e2ea8ae-7bd4-4fbb-b204-926febee3831"
      },
      "source": [
        "#CalibratedClassifier\n",
        "# fit a model\n",
        "model = MultinomialNB(alpha=grid.best_estimator_.alpha)\n",
        "calibrated = CalibratedClassifierCV(model, method='sigmoid',cv=3)\n",
        "calibrated.fit(X_train, y_train)\n",
        "# predict probabilities\n",
        "pred_probs = calibrated.predict_proba(X_test)\n",
        "# to avoid rounding error while multiplying probabilites we use log-probability estimates\n",
        "print(\"Log Loss :\",log_loss(y_test, pred_probs))\n",
        "print(\"Number of missclassified point :\", np.count_nonzero((calibrated.predict(X_test)- y_test))/y_test.shape[0])\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log Loss : 1.232625701111324\n",
            "Number of missclassified point : 0.38646616541353385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZnnWClYrj8J",
        "colab_type": "text"
      },
      "source": [
        "## K Nearest Neighbour Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLUX5sj_rj8L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "f39f1c20-13f3-4547-9f81-cdda5f837144"
      },
      "source": [
        "# KNearest Neigbour\n",
        "model =KNeighborsClassifier()\n",
        "#create a dictionary of all values we want to test for n_neighbors\n",
        "param_grid ={'n_neighbors':[1,4,7,10,13]}\n",
        "#use gridsearch to test all values for n_neighbors\n",
        "grid=GridSearchCV(estimator=model,param_grid=param_grid,cv=3)\n",
        "#fit model to data\n",
        "grid.fit(X_train, y_train)\n",
        "print(grid)\n",
        "#result summary\n",
        "print(grid.best_score_)\n",
        "print(grid.best_estimator_.n_neighbors)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
            "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
            "                                            metric='minkowski',\n",
            "                                            metric_params=None, n_jobs=None,\n",
            "                                            n_neighbors=5, p=2,\n",
            "                                            weights='uniform'),\n",
            "             iid='warn', n_jobs=None,\n",
            "             param_grid={'n_neighbors': [1, 4, 7, 10, 13]},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=None, verbose=0)\n",
            "0.5568524096385542\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31tf7AXnrj8P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "a244a0b2-0c1e-4fd8-c3b5-82bf2840c908"
      },
      "source": [
        "#predicting using best n_neighbors\n",
        "n_neighbors=grid.best_estimator_.n_neighbors\n",
        "model = KNeighborsClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred=model.predict(X_test)\n",
        "score=accuracy_score(y_test,y_pred)\n",
        "print(score)\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5278195488721804\n",
            "[[ 61   3   0  21  14   3   1   0   0]\n",
            " [  3  43   0   2   3   3  38   0   0]\n",
            " [  1   0   3   7   4   0   9   0   0]\n",
            " [ 32   0   3  90  11   1   7   0   0]\n",
            " [ 11   2   4   4  26   6   7   0   0]\n",
            " [  9   7   0   1  11  20   3   0   0]\n",
            " [  9  43   8  10   6   2 105   0   0]\n",
            " [  0   1   0   1   0   0   0   0   0]\n",
            " [  0   0   0   0   1   0   1   1   3]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.48      0.59      0.53       103\n",
            "           2       0.43      0.47      0.45        92\n",
            "           3       0.17      0.12      0.14        24\n",
            "           4       0.66      0.62      0.64       144\n",
            "           5       0.34      0.43      0.38        60\n",
            "           6       0.57      0.39      0.47        51\n",
            "           7       0.61      0.57      0.59       183\n",
            "           8       0.00      0.00      0.00         2\n",
            "           9       1.00      0.50      0.67         6\n",
            "\n",
            "    accuracy                           0.53       665\n",
            "   macro avg       0.47      0.41      0.43       665\n",
            "weighted avg       0.54      0.53      0.53       665\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlN2cExmrj8W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "799ca89e-19fe-4fb7-9be6-060eb4782481"
      },
      "source": [
        "#CalibratedClassifier\n",
        "# fit a model\n",
        "model = KNeighborsClassifier(n_neighbors=grid.best_estimator_.n_neighbors)\n",
        "calibrated = CalibratedClassifierCV(model, method='sigmoid',cv=3)\n",
        "calibrated.fit(X_train, y_train)\n",
        "# predict probabilities\n",
        "pred_probs = calibrated.predict_proba(X_test)\n",
        "# to avoid rounding error while multiplying probabilites we use log-probability estimates\n",
        "print(\"Log Loss :\",log_loss(y_test, pred_probs))\n",
        "print(\"Number of missclassified point :\", np.count_nonzero((calibrated.predict(X_test)- y_test))/y_test.shape[0])\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log Loss : 1.225811202761413\n",
            "Number of missclassified point : 0.44360902255639095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xv5HqKUFrj8a",
        "colab_type": "text"
      },
      "source": [
        "# Linear Classifier SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsMhtQhtrj8c",
        "colab_type": "code",
        "colab": {},
        "outputId": "0a1d3259-450e-4962-ac50-5f6f58049832"
      },
      "source": [
        "#linear_model.SGDClassifier\n",
        "model = linear_model.SGDClassifier(class_weight='balanced', penalty='l2', loss='log', random_state=42)\n",
        "alphas = [1.e-10,1.e-5, 1.e-3,1.e-1,0.1, 0.5, 1]\n",
        "grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas),cv=3)\n",
        "grid.fit(X_train, y_train)\n",
        "print(grid)\n",
        "#result summary\n",
        "print(grid.best_score_)\n",
        "print(grid.best_estimator_.alpha)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
            "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',\n",
            "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
            "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
            "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
            "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
            "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
            "       fit_params=None, iid='warn', n_jobs=None,\n",
            "       param_grid={'alpha': [1e-10, 1e-05, 0.001, 0.1, 0.1, 0.5, 1]},\n",
            "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
            "       scoring=None, verbose=0)\n",
            "0.6321536144578314\n",
            "1e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdJuAMtRrj8h",
        "colab_type": "code",
        "colab": {},
        "outputId": "eab0cb42-04c7-41fb-b04a-4abb0276b765"
      },
      "source": [
        "#predicting using best alpha\n",
        "alpha=grid.best_estimator_.alpha\n",
        "model =linear_model.SGDClassifier(class_weight='balanced', alpha=alpha, penalty='l2', loss='log', random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred=model.predict(X_test)\n",
        "score=accuracy_score(y_test,y_pred)\n",
        "print(score)\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.649624060150376\n",
            "[[ 66   2   0  19   8   7   0   0   1]\n",
            " [  0  69   0   1   2   3  17   0   0]\n",
            " [  1   1   6   8   2   0   6   0   0]\n",
            " [ 24   2   3 103   7   2   2   0   1]\n",
            " [  7   2   1   8  30   4   6   0   2]\n",
            " [  5   5   3   2   3  29   4   0   0]\n",
            " [  6  42   0   3   6   2 124   0   0]\n",
            " [  0   1   0   0   0   0   0   1   0]\n",
            " [  0   0   0   0   0   0   1   1   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.61      0.64      0.62       103\n",
            "           2       0.56      0.75      0.64        92\n",
            "           3       0.46      0.25      0.32        24\n",
            "           4       0.72      0.72      0.72       144\n",
            "           5       0.52      0.50      0.51        60\n",
            "           6       0.62      0.57      0.59        51\n",
            "           7       0.78      0.68      0.72       183\n",
            "           8       0.50      0.50      0.50         2\n",
            "           9       0.50      0.67      0.57         6\n",
            "\n",
            "   micro avg       0.65      0.65      0.65       665\n",
            "   macro avg       0.58      0.59      0.58       665\n",
            "weighted avg       0.66      0.65      0.65       665\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwpcJJ6trj8m",
        "colab_type": "code",
        "colab": {},
        "outputId": "7c0d39cb-eab3-43a1-c7f8-801f475bc9c4"
      },
      "source": [
        "#CalibratedClassifier\n",
        "# fit a model\n",
        "model = linear_model.SGDClassifier(class_weight='balanced', penalty='l2', loss='log', random_state=42,alpha=grid.best_estimator_.alpha)\n",
        "calibrated = CalibratedClassifierCV(model, method='sigmoid',cv=3)\n",
        "calibrated.fit(X_train, y_train)\n",
        "# predict probabilities\n",
        "pred_probs = calibrated.predict_proba(X_test)\n",
        "# to avoid rounding error while multiplying probabilites we use log-probability estimates\n",
        "print(\"Log Loss :\",log_loss(y_test, pred_probs))\n",
        "print(\"Number of missclassified point :\", np.count_nonzero((calibrated.predict(X_test)- y_test))/y_test.shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "C:\\Users\\Gerald\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Log Loss : 1.0298348126904542\n",
            "Number of missclassified point : 0.33383458646616543\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTWY5vT5rj8r",
        "colab_type": "text"
      },
      "source": [
        "# Linear Classifier SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO21grN3rj8u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "outputId": "02f667ec-81e0-4863-8706-7ed982c2ad79"
      },
      "source": [
        "#linear_model.SGDClassifier\n",
        "model = SVC()\n",
        "C = [1.e-10,1.e-5, 1.e-3,1.e-1,0.1, 0.5, 1]\n",
        "grid = GridSearchCV(estimator=model, param_grid=dict(C=C),cv=3)\n",
        "grid.fit(X_train, y_train)\n",
        "print(grid)\n",
        "#result summary\n",
        "print(grid.best_score_)\n",
        "print(grid.best_estimator_.C)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
            "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
            "                           decision_function_shape='ovr', degree=3,\n",
            "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
            "                           probability=False, random_state=None, shrinking=True,\n",
            "                           tol=0.001, verbose=False),\n",
            "             iid='warn', n_jobs=None,\n",
            "             param_grid={'C': [1e-10, 1e-05, 0.001, 0.1, 0.1, 0.5, 1]},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=None, verbose=0)\n",
            "0.28990963855421686\n",
            "1e-10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p73mIr8irj80",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "01c42856-3571-40b1-e49d-45a9f664c1e7"
      },
      "source": [
        "#predicting using best alpha\n",
        "alpha=grid.best_estimator_.C\n",
        "model =SVC()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred=model.predict(X_test)\n",
        "score=accuracy_score(y_test,y_pred)\n",
        "print(score)\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.27518796992481204\n",
            "[[  0   0   0   0   0   0 103   0   0]\n",
            " [  0   0   0   0   0   0  92   0   0]\n",
            " [  0   0   0   0   0   0  24   0   0]\n",
            " [  0   0   0   0   0   0 144   0   0]\n",
            " [  0   0   0   0   0   0  60   0   0]\n",
            " [  0   0   0   0   0   0  51   0   0]\n",
            " [  0   0   0   0   0   0 183   0   0]\n",
            " [  0   0   0   0   0   0   2   0   0]\n",
            " [  0   0   0   0   0   0   6   0   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00       103\n",
            "           2       0.00      0.00      0.00        92\n",
            "           3       0.00      0.00      0.00        24\n",
            "           4       0.00      0.00      0.00       144\n",
            "           5       0.00      0.00      0.00        60\n",
            "           6       0.00      0.00      0.00        51\n",
            "           7       0.28      1.00      0.43       183\n",
            "           8       0.00      0.00      0.00         2\n",
            "           9       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.28       665\n",
            "   macro avg       0.03      0.11      0.05       665\n",
            "weighted avg       0.08      0.28      0.12       665\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRkI7AEYrj88",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "78ac2e91-ebc3-4400-d38d-a73d1affa7aa"
      },
      "source": [
        "#CalibratedClassifier\n",
        "# fit a model\n",
        "model = SVC()\n",
        "calibrated = CalibratedClassifierCV(model, method='sigmoid',cv=3)\n",
        "calibrated.fit(X_train, y_train)\n",
        "# predict probabilities\n",
        "pred_probs = calibrated.predict_proba(X_test)\n",
        "# to avoid rounding error while multiplying probabilites we use log-probability estimates\n",
        "print(\"Log Loss :\",log_loss(y_test, pred_probs))\n",
        "print(\"Number of missclassified point :\", np.count_nonzero((calibrated.predict(X_test)- y_test))/y_test.shape[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Log Loss : 1.2598962550069057\n",
            "Number of missclassified point : 0.4105263157894737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLo0PDdbrj9B",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVV3-HMwrj9D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "41ed196a-33bf-409e-d61f-bdc24d968c03"
      },
      "source": [
        "#RandomForestClassifier\n",
        "model=RandomForestClassifier()\n",
        "# using a full grid over all parameters\n",
        "param_grid = {\"max_depth\": [3, None],\n",
        "              \"max_features\": [1, 3, 10],\n",
        "              \"min_samples_split\": [2, 3, 10],\n",
        "              \"bootstrap\": [True, False],\n",
        "              \"criterion\": [\"gini\", \"entropy\"]}\n",
        "# trainning over the grid\n",
        "grid_search = GridSearchCV(model, param_grid=param_grid, cv=5, iid=False,verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed: 12.2min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
              "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators='warn', n_jobs=None,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid=False, n_jobs=None,\n",
              "             param_grid={'bootstrap': [True, False],\n",
              "                         'criterion': ['gini', 'entropy'],\n",
              "                         'max_depth': [3, None], 'max_features': [1, 3, 10],\n",
              "                         'min_samples_split': [2, 3, 10]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDR3klkirj9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_param_grid = grid_search.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCe6oolArj9O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "7ce4a812-749e-4653-d3b1-6086c848604f"
      },
      "source": [
        "print(best_param_grid)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
            "                       max_depth=None, max_features=1, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=3,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tt_4yVwrj9W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "195359ec-32ba-43c1-abbd-4d6c10e79688"
      },
      "source": [
        "#prediction with best grid search params\n",
        "model=RandomForestClassifier(best_param_grid)\n",
        "y_pred=grid_search.predict(X_test)\n",
        "score=accuracy_score(y_test,y_pred)\n",
        "print(score)\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5939849624060151\n",
            "[[ 70   4   0  14   5   4   6   0   0]\n",
            " [  6  31   0   7   1   0  47   0   0]\n",
            " [  5   1   5   7   0   0   6   0   0]\n",
            " [ 25   3   1 106   1   1   7   0   0]\n",
            " [ 28   1   2   4   9   5   9   0   2]\n",
            " [ 14   2   0   2   2  25   6   0   0]\n",
            " [  7  17   1   7   5   2 144   0   0]\n",
            " [  0   1   0   0   0   0   0   1   0]\n",
            " [  0   0   0   0   0   0   1   1   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.45      0.68      0.54       103\n",
            "           2       0.52      0.34      0.41        92\n",
            "           3       0.56      0.21      0.30        24\n",
            "           4       0.72      0.74      0.73       144\n",
            "           5       0.39      0.15      0.22        60\n",
            "           6       0.68      0.49      0.57        51\n",
            "           7       0.64      0.79      0.70       183\n",
            "           8       0.50      0.50      0.50         2\n",
            "           9       0.67      0.67      0.67         6\n",
            "\n",
            "    accuracy                           0.59       665\n",
            "   macro avg       0.57      0.51      0.52       665\n",
            "weighted avg       0.59      0.59      0.57       665\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N2gFIrYrj9e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1b3fef96-4225-401a-d174-cb77bf930338"
      },
      "source": [
        "#CalibratedClassifier\n",
        "# fit a model\n",
        "model=RandomForestClassifier(min_samples_leaf=1,max_features=1,n_estimators=10)\n",
        "calibrated = CalibratedClassifierCV(model, method='sigmoid',cv=3)\n",
        "calibrated.fit(X_train, y_train)\n",
        "# predict probabilities\n",
        "pred_probs = calibrated.predict_proba(X_test)\n",
        "# to avoid rounding error while multiplying probabilites we use log-probability estimates\n",
        "print(\"Log Loss :\",log_loss(y_test, pred_probs))\n",
        "print(\"Number of missclassified point :\", np.count_nonzero((calibrated.predict(X_test)- y_test))/y_test.shape[0])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log Loss : 1.216412066325453\n",
            "Number of missclassified point : 0.38646616541353385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfleyxhOrj9j",
        "colab_type": "code",
        "colab": {},
        "outputId": "801dbbfd-94f4-4b10-d0fc-c0efa96f0ff4"
      },
      "source": [
        "# Predicting a Class\n",
        "test_point=6\n",
        "test_data=X_test[test_point].reshape(1, -1)\n",
        "prediction=grid_search.predict(test_data)\n",
        "prediction_probabilities=calibrated.predict_proba(test_data)\n",
        "Actual_result=y_test[test_point]\n",
        "print('prediction: ',prediction)\n",
        "print('prediction_probabilities: ',prediction_probabilities)\n",
        "print('Actual_result:',Actual_result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prediction:  [1]\n",
            "prediction_probabilities:  [[0.42580632 0.08371896 0.02191428 0.18178263 0.06007569 0.02803446\n",
            "  0.1818259  0.00933916 0.00750261]]\n",
            "Actual_result: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_kJOqK1GbjN",
        "colab_type": "text"
      },
      "source": [
        "## SGD has been the best performer"
      ]
    }
  ]
}